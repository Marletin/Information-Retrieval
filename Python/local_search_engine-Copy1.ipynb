{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100%; !important } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "display(HTML('<style>.container { width:100%; !important } </style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import magic\n",
    "import math\n",
    "import os\n",
    "import string\n",
    "import platform\n",
    "import operator\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, url, length, id, textList):\n",
    "        self.url = url\n",
    "        self.length = length\n",
    "        self.id = id\n",
    "        self.score = 0.\n",
    "        self.textList = textList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Index:\n",
    "    hashmap = {} #dictionary\n",
    "    fileCount = 0 #integer, Gesamtzahl aller gefunden Dateien\n",
    "    docHashmap = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildIndex(self):\n",
    "    \n",
    "    #startDirectories = self._getStartDirectories()\n",
    "    startDirectories = [r\"M:\\Studium\"]\n",
    "    mime = magic.Magic(mime=True)\n",
    "    \n",
    "    for directory in startDirectories:\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                \n",
    "                path = os.path.abspath(os.path.join(root, file))\n",
    "                \n",
    "                try:\n",
    "                    if mime.from_file(path) == \"application/pdf\":\n",
    "\n",
    "                        fileData = parser.from_file(path)\n",
    "                        rawText = fileData['content']\n",
    "                        self.fileCount += 1\n",
    "                    \n",
    "                        processedText = self._preprocessText(rawText)\n",
    "                        document = Document(path, len(processedText), self.fileCount, processedText)\n",
    "                        self.docHashmap.update({self.fileCount : document})\n",
    "                        self._addToIndex(self.fileCount, processedText)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "Index.buildIndex = buildIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _getStartDirectories(self):\n",
    "\n",
    "    if platform.system() == \"Linux\":\n",
    "        directories = [\"/\"]\n",
    "        \n",
    "    elif platform.system() == \"Darwin\":\n",
    "        directories = [\"/\"]\n",
    "        \n",
    "    elif platform.system() == \"Windows\":\n",
    "        directories = ['%s:\\\\' % d for d in string.ascii_uppercase if os.path.exists('%s:' % d)]\n",
    "        \n",
    "    else:\n",
    "        raise EnvironmentError\n",
    "        \n",
    "    return directories\n",
    "\n",
    "Index._getStartDirectories = _getStartDirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _addToIndex(self, documentID, terms):\n",
    "    \n",
    "    for term in terms:\n",
    "        \n",
    "        try:\n",
    "            docSet = self.hashmap[term]\n",
    "            docSet.add(documentID)\n",
    "            self.hashmap.update({term : docSet})\n",
    "            \n",
    "        except KeyError:\n",
    "            docSet = {documentID}\n",
    "            self.hashmap.update({term : docSet})\n",
    "    \n",
    "Index._addToIndex = _addToIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _preprocessText(self, text):\n",
    "    \n",
    "    lowerText = text.lower()\n",
    "    \n",
    "    prepText = re.sub(r'\\d+', '', lowerText)\n",
    "            \n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z]+-$|\\w+')\n",
    "    tokenList = tokenizer.tokenize(prepText)\n",
    "    \n",
    "    for token in tokenList:\n",
    "        if token[-1] == '-':\n",
    "            \n",
    "            index = tokenList.index(token)\n",
    "            compositeWord = token[:-1]+tokenList[index+1]\n",
    "            tokenList[index] = compositeWord\n",
    "            del tokenList[index+1]\n",
    "            \n",
    "    return tokenList\n",
    "    \n",
    "Index._preprocessText = _preprocessText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPROVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(self, searchString):\n",
    " \n",
    "    processedStrings = self._preprocessText(searchString)\n",
    "    result, intsect = set(), set()\n",
    "    df, helpDict, helpDict2 = {}, {}, {}\n",
    "    resultList, resultList2 = [], []\n",
    "    \n",
    "    for word in processedStrings:\n",
    "        try:\n",
    "            documents = set(self.hashmap[word])\n",
    "            df[word] = len(documents)\n",
    "            intsect = result.intersection(documents).union(intsect)\n",
    "            result = result.union(documents)\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    for document in result:\n",
    "        doc = ind.docHashmap[document]\n",
    "        doc.tf_idf(processedStrings,df)\n",
    "        helpDict[doc.id] = doc.score\n",
    "        \n",
    "    for key in intsect:\n",
    "        helpDict2[key] = helpDict[key]\n",
    "        helpDict.pop(key)\n",
    "        \n",
    "    sortedDict = sorted(helpDict.items(), key=operator.itemgetter(1))\n",
    "    sortedDict2 = sorted(helpDict2.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    \n",
    "    for key,_ in sortedDict:\n",
    "        resultList.append(ind.docHashmap[key].url)\n",
    "    \n",
    "    for key,_ in sortedDict2:\n",
    "        resultList2.append(ind.docHashmap[key].url)\n",
    "    \n",
    "    \n",
    "    resultList = resultList[::-1]\n",
    "    resultList2 = resultList2[::-1]\n",
    "    \n",
    "    return resultList2+resultList\n",
    "\n",
    "Index.retrieve = retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(self, termList, df):\n",
    "    \n",
    "    tfDict = {}\n",
    "    for term in termList:\n",
    "        tfDict[term] = 0\n",
    "    \n",
    "    ind = Index()\n",
    "        \n",
    "    for term in self.textList:\n",
    "        if term in termList:\n",
    "            tfDict[term] = tfDict[term]+1\n",
    "\n",
    "    for key, value in df.items():\n",
    "        idf = math.log((ind.fileCount+1/value+1),10)\n",
    "        tfDict[key] = tfDict[key]*idf\n",
    "    \n",
    "    self.score = sum(tfDict.values())\n",
    "\n",
    "Document.tf_idf = tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = Index()\n",
    "ind.buildIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M:\\Studium\\Praxisbericht_3\\T3000_TINF16AIBI_Richter_Jesse-Jermaine.pdf\n",
      "M:\\Studium\\T2000\\Scan_JesseRichter_20180914124926.pdf\n",
      "M:\\Studium\\Praxisbericht_3\\Bewertung\\Drucken.pdf\n",
      "M:\\Studium\\Praxisbericht_3\\Bewertung\\Ablauf_und_Reflexion_der_Praxisphase_Teil_B.pdf\n",
      "M:\\Studium\\Praxisbericht_2\\Monitoring.pdf\n",
      "M:\\Studium\\Praxisbericht_2\\Monitoring-LAPTOP-2NADN4MG.pdf\n",
      "M:\\Studium\\Praxisbericht_2\\Monitoring-LAPTOP-2NADN4MG-2.pdf\n",
      "M:\\Studium\\Java\\Folien.pdf\n",
      "M:\\Studium\\Java\\Klausurrelevant.pdf\n",
      "M:\\Studium\\Web Engineering 2\\restful-java-with-jax-rs-2-0-2rd-edition-en.pdf\n",
      "M:\\Studium\\Verteilte Systeme\\Folien\\03-RMI.pdf\n",
      "M:\\Studium\\Compilerbau\\Java_Haskell_Compiler.pdf\n",
      "M:\\Studium\\Compilerbau\\Java_Haskell_Compiler3.pdf\n",
      "M:\\Studium\\Web Engineering 2\\5.1-JSP.pdf\n",
      "M:\\Studium\\Algorithmen\\algorithms.pdf\n",
      "M:\\Studium\\Formale Sprachen & Automaten\\KIT_Formale-Sprachen[881].pdf\n",
      "M:\\Studium\\Datenbanken\\10 Datenbanken I - Wiederholung, Vertiefung und Zusatzthemen.pdf\n",
      "M:\\Studium\\Compilerbau\\Java_Haskell_Compiler1.pdf\n",
      "M:\\Studium\\Compilerbau\\Java_Haskell_Compiler5.pdf\n",
      "M:\\Studium\\Java\\Klausur Java-Programmierung SS 2012.pdf\n",
      "M:\\Studium\\Big Data\\Vorlesung\\BigDataAnalytics-Lecture-04.pdf\n",
      "M:\\Studium\\Web Engineering 2\\2.2-WBA-Architecture.pdf\n",
      "M:\\Studium\\Compilerbau\\folien-01.pdf\n",
      "M:\\Studium\\Compilerbau\\Java_Haskell_Compiler2.pdf\n",
      "M:\\Studium\\Verteilte Systeme\\Folien\\04-Namensdienste.pdf\n",
      "M:\\Studium\\Datenbanken II\\Datenbanken II.pdf\n",
      "M:\\Studium\\Compilerbau\\Java_Haskell_Compiler4.pdf\n",
      "M:\\Studium\\C\\Nachschreibklausur_Pr.pdf\n",
      "M:\\Studium\\Web Engineering\\20161208-Vorlesung-06.pdf\n",
      "M:\\Studium\\Verteilte Systeme\\Folien\\02-Middleware.pdf\n",
      "M:\\Studium\\Software Engineering 2\\2_DesignPatterns-MusterKlassifikation.pdf\n",
      "M:\\Studium\\C\\Klausur_J2.pdf\n",
      "M:\\Studium\\Web Engineering\\20170112-Vorlesung-08.pdf\n",
      "M:\\Studium\\E-Business\\E_COMMERCE_2017_1.pdf\n",
      "M:\\Studium\\Web Engineering 2\\1.2-servlets.pdf\n",
      "M:\\Studium\\C\\Klausur_J.pdf\n",
      "M:\\Studium\\Betriebssysteme\\betriebssysteme-01-17-09-21.pdf\n",
      "M:\\Studium\\Big Data\\Vorlesung\\BigDataAnalytics-Lecture-02.pdf\n",
      "M:\\Studium\\Web Engineering 2\\1.2-HTTP.pdf\n",
      "M:\\Studium\\Web Engineering 2\\3.1-Authentisierung_WebAppls.pdf\n",
      "M:\\Studium\\Verteilte Systeme\\Folien\\05-Prozessmanagement.pdf\n",
      "M:\\Studium\\Software Architecture Management\\SoftwareArchitektur_folien.pdf\n",
      "M:\\Studium\\IT-Sicherheit\\Vorlesungen\\2_Web_Anwendungen.pdf\n",
      "M:\\Studium\\IT-Sicherheit\\Zusammenfassung.pdf\n",
      "M:\\Studium\\Interaktive Systeme\\04 Interaktive Systeme - Hoeren.pdf\n",
      "M:\\Studium\\Compilerbau\\blatt2.pdf\n",
      "M:\\Studium\\Analysis\\analysis.pdf\n",
      "M:\\Studium\\Web Engineering 2\\5.4-ServerPush.pdf\n",
      "M:\\Studium\\Web Engineering 2\\5.2-Filterss.pdf\n",
      "M:\\Studium\\Web Engineering 2\\3.3-Servlets-API.pdf\n",
      "M:\\Studium\\Web Engineering\\20161027-Vorlesung-01.pdf\n",
      "M:\\Studium\\Studienarbeit\\irbookonlinereading.pdf\n",
      "M:\\Studium\\Logik\\logic.pdf\n",
      "M:\\Studium\\Kommunikations- Netzwerktechnik\\KT\\VKT00_Organisation_180213.pdf\n",
      "M:\\Studium\\Interaktive Systeme\\02 Interaktive Systeme - Sehen.pdf\n",
      "M:\\Studium\\Datenbanken\\Zusammenfassungen\\04 Relationale Modell und Algebra.pdf\n",
      "M:\\Studium\\Datenbanken\\Zusammenfassungen\\02 Geschichte und Motivation.pdf\n",
      "M:\\Studium\\Datenbanken\\05 Datenbanken I - Die Sprache SQL.pdf\n",
      "M:\\Studium\\Datenbanken\\02 Datenbanken I - Geschichte_Motivation_Grundlagen.pdf\n",
      "M:\\Studium\\Consulting\\Consulting.pdf\n",
      "M:\\Studium\\Compilerbau\\Compiler.pdf\n",
      "M:\\Studium\\Big Data\\Vorlesung\\BigDataAnalytics-Lecture-05.pdf\n",
      "M:\\Studium\\Big Data\\Vorlesung\\BigDataAnalytics-Lecture-00.pdf\n",
      "M:\\Studium\\Betriebssysteme\\betriebssysteme-02-17-09-28.pdf\n"
     ]
    }
   ],
   "source": [
    "resultSet = ind.retrieve(\"Jesse Richter Java\")\n",
    "if resultSet:\n",
    "    for elem in resultSet:\n",
    "        if elem.split('.')[-1] != 'dat':\n",
    "            print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in [1, 2, 166, 137, 138, 171, 210]:\n",
    "    print(ind.docHashmap[index].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
