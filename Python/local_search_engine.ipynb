{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel-Implementierung: Lokale Suchmaschine\n",
    "\n",
    "## Ziel der Beispiel-Implementierung\n",
    "Im Folgenden wird eine Anwendung der zuvor theoretisch diskutierten Inhalte vorgestellt. Dabei soll eine lokale Suchmaschine entwickelt werden, welche in der Lage ist, pdf-Dateien auf einem lokalen Computer-System zu parsen, in einen invertierten Index aufzunehmen sowie Suchanfragen eines Benutzers sinnvoll zu beantworten. <br>\n",
    "Zur Relevanz-Bestimmung der Dokumente wird das TF-IDF-Maß, welches bereits vorgestellt wurde, genutzt. Um den Index zu speichern, wird die von Python mitgelieferte Datenstruktur \"dictionary\", welche im Grunde eine Hashmap ist, genutzt.\n",
    "Weiter werden einige Bibliotheken eingesetzt, welche einige Vorarbeit leisten und damit den Code der Beispiel-Implementierung auf das Wesentliche beschränken. So soll die grundlegende Arbeitsweise eines Information Retrieval-Systems dargelegt werden.\n",
    "\n",
    "## Genutzte Bibliotheken\n",
    "Bevor mit der eigentlichen Implementierung der lokalen Suchmaschine begonnen werden kann, müssen einige Bibliotheken eingebunden werden. Darunter fallen Apache Tika, das Math-Modul von Python, os (um auf die Directories zugreifen zu können), python-magic, regular expressions (re) (und noch weitere, bei Bedarf einfügen!). <br>\n",
    "\n",
    "### Tika\n",
    "Tika liefert eine Parser, mit dessen Hilfe der Text aus - unter anderem - pdf-Dateien extrahiert werden kann.\n",
    "Mit dem Aufruf _parser.from_\\__file(file)_ kann eine pdf-Datei in reinen Text umgewandelt werden. Die Funktion liefert ein Dictionary zurück, welches einen Key _content_ besitzt, über den auf den Inhalt der pdf-Datei zugegriffen werden kann.\n",
    "\n",
    "### python-magic\n",
    "Mittels python-magic ist es möglich, unabhängig von der Dateiendung, den Typ einer Datei zu ermitteln. Dies hat den Vorteil, dass die Suchmaschine sowohl unter Windows, als auch unter Unix-Systemen, alle pdf-Dateien finden kann, da unter Unix die Dateiendung keine garantierten Rückschlüsse auf den Typ der Datei zulässt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import magic\n",
    "import math\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Index\n",
    "Nachdem die benötigten Bibliotheken bekannt sind, kann der Index implementiert werden. Bevor dieser jedoch aufgebaut werden kann, sind einige Vorarbeiten nötig, die durch die vorgestellten Bibliotheken gestützt werden.\n",
    "Der Index wird im Folgenden als Klasse implementiert. Diese beinhaltet die folgenden Methoden, die in den folgenden Abschnitten genauer diskutiert werden:\n",
    "- buildIndex()\n",
    "- retrieve()\n",
    "- calcTFIDF()\n",
    "\n",
    "Weiter werden die folgenden Member-Variablen benötigt:\n",
    "- hashmap\n",
    "- fileCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    hashmap = {} #dictionary\n",
    "    fileCount = 0 #integer, Gesamtzahl aller gefunden Dateien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buildIndex\n",
    "Die Methode _buildIndex_ baut - wie der Name bereits vermuten lässt - den Index auf. Dabei dient ein Dictionary als Basis-Datenstruktur. Zudem führt diese Methode die Verarbeitung der pdf-Dateien mittels Apache tika und python-magic durch.\n",
    "\n",
    "Der erste Schritt stellt das Iterieren über alle Directories dar. Gestartet wird bei Linux-Systemen im Root-Directory, unter Windows-Systemen muss über jede Partition iteriert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildIndex(self):\n",
    "    # alle Start-Verzeichnisse holen\n",
    "    #start = self.__getStartDirectories()\n",
    "    start = [\"C:/Users/jonas/Uni/Praxisbericht/Praxisbericht 5. Semester/Latex\"]\n",
    "    # Magic-Instanz erstellen, um Datei-Typ bestimmen zu können\n",
    "    mime = magic.Magic(mime=True)\n",
    "    \n",
    "    for s in start:\n",
    "        for subdir, dir, files in os.walk(s):\n",
    "            for f in files:\n",
    "                if mime.from_file(s+\"/\"+f) == \"application/pdf\":\n",
    "                    # in Text umwawndeln und tokenization durchführen\n",
    "                    fileData = parser.from_file(s+\"/\"+f)\n",
    "                    rawText = fileData['content']\n",
    "                    \n",
    "                    self.__preprocessText(rawText)\n",
    "                    \n",
    "    return\n",
    "\n",
    "Index.buildIndex = buildIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilfsmethoden\n",
    "In diesem Abschnitt werden die genutzten Hilfsmethoden kurz vorgestellt. Diese werden jedoch nicht in der Tiefe behandelt, wie die drei Haupt-Methoden behandelt werden. \n",
    "\n",
    "#### __getStartDirectories\n",
    "Die Methode _\\_\\_getSartDirectories_ liefert eine Liste zurück, welche abhängig vom Betriebssystem, auf dem die Suchmaschine läuft, die Start-Verzeichnisse zurückgibt, in denen nach pdf-Dateien gesucht werden soll. Falls das zugrunde liegende Betriebssystem ein Linux-basiertes System ist, wird die Liste __[\"/\"]__ zurückgegeben, falls ein Windows-System zugrundeliegt, wird die Liste aller Partitionen zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getStartDirectories(self):\n",
    "    start = []\n",
    "    \n",
    "    if platform.system() == \"Linux\":\n",
    "        start.append(\"/\")\n",
    "    elif platform.system() == \"Windows\":\n",
    "        start = ['%s:' % d for d in string.ascii_uppercase if os.path.exists('%s:' % d)]\n",
    "    else:\n",
    "        raise EnvironmentError\n",
    "        \n",
    "    return start\n",
    "\n",
    "Index.__getStartDirectories = __getStartDirectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __addToIndex\n",
    "\n",
    "Diese Methode bekommt als Argument einen String, welcher den von tika extrahierten Text enthält. Dieser String wird mithilfe der in Python enthaltenen Methode _split_ aufgeteilt und in einer Liste zusammengefasst. Weiter werden Satzzeichen wie Punkte, Kommata, etc. aus dem String bzw. der Liste herausgefiltert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __addToIndex(self, text):\n",
    "    # string zu Liste machen, dabei Punkt, Komma etc. rauswerfen\n",
    "    forbidden = \".,?!'\\\";:-\"\n",
    "    textList = [word for word in text.split() if word not in forbidden]\n",
    "    print(textList[:100])\n",
    "    # Post-processing der Wort-Liste\n",
    "    \n",
    "    \n",
    "Index.__addToIndex = __addToIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __preprocessText(self, txt):\n",
    "    # lower all:\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r'\\d+', '', txt)\n",
    "    intermediate = txt.split('\\n')\n",
    "    toTokenize = \"\"\n",
    "    for line in intermediate:\n",
    "        if line != '' and line[-1] == \"-\":\n",
    "            i = intermediate.index(line)\n",
    "            nextWords = intermediate[i+1].split()\n",
    "            newLine = line + nextWords[0]\n",
    "            newLine = newLine[1:]\n",
    "            intermediate[i+1] = \"\".join(newLine)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    result = tokenizer.tokenize(toTokenize)\n",
    "    print(result[:100])\n",
    "    return result\n",
    "    \n",
    "Index.__preprocessText = __preprocessText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-e7799879dc27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-105-535ce5b8a957>\u001b[0m in \u001b[0;36mbuildIndex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mrawText\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfileData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preprocessText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawText\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-160-05fd23707e2e>\u001b[0m in \u001b[0;36m__preprocessText\u001b[1;34m(self, txt)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintermediate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mnextWords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintermediate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mnewLine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnextWords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mnewLine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewLine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mintermediate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewLine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ind = Index()\n",
    "ind.buildIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
