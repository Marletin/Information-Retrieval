In der Vorgestellten Implementierung gibt es einige Probleme und daraus folgende Verbesserungen, die in diesem Abschnitt besprochen werden.

Die folgende Liste dient nur zur Dokumentation der vorhanden Probleme und wird später durch ausführlichere Erläuterungen und Beispielen ersetzt.
\begin{itemize}
	\item BuildIndex Laufzeit verringern
	\begin{itemize}
		\item Mit Threads parallelisieren?
	\end{itemize}
	\item Invertierten Index persistieren, damit er nicht immer wieder neu aufgebaut werden muss
	\begin{itemize}
		\item Wie soll persistiert werden?
		\item Wie sollen nur Verzeichnisse mit Änderungen (Löschung/Erstellung von PDF) erkannt werden?
		\item Wann sollen Aktualisierungen durchgeführt werden?
	\end{itemize}
	\item *.dat Dateien werden als PDFs erkannt
	\item Implementierung von Stemming?
	\item RAM-Auslastung durch Speicherung der Terme der Dokumente als Liste in Document-Klasse hoch. Verlangsamt BuildINdex, beschleunigt aber Retrieve.
	\item Kontext der Wörter wird nicht beachtet (Bags of Words Modell)
	\begin{itemize}
		\item N-Gramm nutzen? (Speichern von zwei aufeinander treffende Wörter als Token)
	\end{itemize}
\end{itemize}

\section{Probleme der aktuellen Beispiel-Implementierung}
Dieser Abschnitt wird eine kurze Problemanalyse der aktuellen Implementierung der lokalen Suchmaschine liefern. Zu diesem Zweck soll die NPL-Test-Collection herangezogen werden. Mit deren Hilfe kann ermittelt werden, wie \glqq gut\grqq\ die Suchmaschine ist. Dazu werden zwei Messungen vorgenommen:
\begin{itemize}
	\item Die $precision$ gibt den Anteil an, wie viele der gefundenen Dokumente relevant sind.
	\item Der $recall$ gibt an, wie viele der relevanten Dokumente gefunden werden.
\end{itemize}

\subsection{Analyse der Precision}
Die Precision ist wie folgt definiert:
\begin{center}
	$precision = \frac{r_1}{r_2}$,
\end{center}
wobei $r_1$ die Anzahl der ermittelten, relevanten Dokumente ist und $r_2$ die Anzahl aller ermittelten Dokumente.
\\
In der NPL-Collection sind $11.429$ Dokumente vorhanden, zudem sind $93$ Queries mitgeliefert. Den Queries liegen darüber hinaus alle Dokumenten-IDs bei, die für die Query relevant sind. Falls die Suchmaschine genau die einer Query zugeordneten Dokumenten zurückliefert, wird die $precision$ $1$.
Wird der Wert der $precision$ $\ge$ $0,8$, ist das Ergebnis bereits ausreichend gut.

\subsubsection{Test und Auswertung der Ergebnisse}

\subsubsection{Lösungsvorschläge}

\subsection{Analyse des Recalls}
Der Recall ist definiert als
\begin{center}
	$recall = \frac{r_1}{r_2}$, 
\end{center}
wobei $r_1$ die Anzahl der ermittelten, relevanten Dokumente ist und $r_2$ die Anzahl relevanter Dokumente ist.
Der $recall$ wird $1$, wenn die Menge der zurückgegebenen Dokumente genau der Menge der relevanten Dokumenten in der Collection entspricht.
Gilt $recall$ $\ge$ $0,8$, ist der Wert ausreichend gut.

\subsubsection{Test und Auswertung der Ergebnisse}

\subsubsection{Lösungsvorschläge}

\subsection{Aufbaudauer des Index}
Der letzte Punkt, der ins Auge fällt, betrifft die Geschwindigkeit, in der der Index aufgebaut wird. Für 189 pdf-Dokumente benötigt die Beispiel-Implementierung ca 1 Minute und 17 Sekunden.
Wird ein System mit ca. 105GB nach pdf-Dateien durchsucht und in den Index aufgenommen, werden auf einem System mit einem Intel Core i5 der 8. Generation und 8 Gigabyte RAM ca. 40 Minuten benötigt. Für einen sinnvollen Einsatz einer lokalen Suchmaschine ist die Suchmaschine somit nicht geeignet. Zwei Ideen, diese Zeit zu senken, sind Parallelisierung und Persistierung.

\subsubsection{Persistierung}
Die Idee, die wahrscheinlich am wirksamsten ist, besteht darin, den Index nach oder bereits während des Aufbaus,  zu persistieren. Durch die Persistierung kann bei einem Neustart der Suchmaschine eine Datei eingelesen werden, welche die Index-Daten beinhaltet. Dadurch ist es nicht nötig, beim Start durch alle Pfade zu gehen und jede Datei zu öffnen, um festzustellen, ob es sich um eine pdf-Datei handelt. Pro Öffnen einer Datei werden mindestens zwei Systemaufrufe benötigt (öffnen und schließen der Datei). Zudem werden weitere Systemaufrufe benötigt, wenn Verzeichnisse geöffnet werden, da diese in der Regel ebenfalls als spezielle Dateien behandelt werden. Das hat zur Folge, dass viele Kontextwechsel stattfinden und das Programm bei jedem Systemaufruf blockiert wird.
\\
Dadurch, dass bei einem persistenten Index initial nur eine Datei geöffnet werden muss, kann ein Großteil der Systemaufrufe und Kontextwechsel verhindert werden. Damit wird viel Zeit gespart. 
\\
Ein Problem, was hier gelöst werden muss ist, alle Dokumente ausfindig zu machen, die noch nicht im Index aufgenommen wurden. Dazu kann eine Liste angelegt werden, die alle im Index vorhandenen Dokumente aufführt. Zudem kann für dieses Problem Parallelisierung genutzt werden, die im Folgenden Abschnitt behandelt wird.

\subsubsection{Parallelisierung}
Durch Nutzung von Parallelisierung kann der Aufbau des Index ebenfalls beschleunigt werden. Da die Beispiel-Implementierung auf Python basiert, ist jedoch zu beachten, dass Python-Threads keine Vorteile Multi-Prozessorsystemen ziehen kann. Das bedeutet, dass mehrere Python-Threads nicht parallel auf verschiedenen Kernen laufen können. Dennoch bringt Parallelisierung einen Geschwindigkeits-Vorteil.
\\
Wird ein Systemaufruf ausgelöst, um beispielsweise eine Datei zu öffnen, wird, sofern die Suchmaschine Single-Threaded ist, das komplette Programm blockiert. Werden jedoch Threads genutzt, kann nur der Thread blockiert werden, der den Systemaufruf verursacht hat. An dessen Stelle kann dann ein weiterer Thread treten, der in der Zwischenzeit rechnen kann. Dadurch wird weniger Zeit mit Warten verschwendet und der Index-Aufbau wird beschleunigt. 
\\
Ist der Index persistent gespeichert, ist es möglich, in regelmäßigen einen oder mehrere Threads zu starten und somit \glqq im Hintergrund\grqq\ nach neuen Dateien gesucht werden, die noch nicht im Index vorhanden sind. 
\\
Durch die Kombination beider Ideen, sollte der Aufbau des Index spürbar beschleunigt werden.

