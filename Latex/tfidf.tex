Bei großen Sammlungen von Dokumenten reicht es nicht aus, wenn das IR-System die Dokumente zurückgibt, welche die Suchanfrage erfüllen. Die Menge der Dokumente, die durch das IR zurückgegebene werden, ist meist zu groß, so dass der Nutzer nicht in der Lage ist alle Dokumente zu sichten und die für ihn relevanten Dokument auszuwählen.\\
Die Frage, die sich hier stellt, ist, wie der Nutzer die Dokumente bekommt, die er mit hoher Wahrscheinlichkeit benötigt. Zur Bestimmung der Wichtigkeit eines Dokuments bzgl. einer Query, wird das sogenannte Scoring eingesetzt. Scoring, oder auch Bewertung, wird genutzt um zu bestimmen, welche Dokumente für die Suchanfrage am relevantesten sind. Es kann auch von einer Gewichtung der Dokumente gesprochen werden.\\
Das Gewichtungsmodell, welches in dieser Arbeit thematisiert und genutzt wird, ist das TF-IDF-Maß. Das TF-IDF-Maß bewertet ein Dokument anhand der Terme, die in der Query stehen, ohne zu beachten, wie diese miteinander verknüpft sind. TF steht hierbei für Term Frequency und IDF für Inverse Document Frequency. Beide Methoden werden einzeln in den folgenden Abschnitten vorgestellt und am Ende zum TF-IDF-Maß verknüpft.

\section{Term Frequency}
Um Dokumente aus einer Kollektion nach Termen einer Suchquery zu gewichten, ist das Zählen jedes einzelnen Terms $t$ einer Query in jedem Dokument $d$ die zunächst trivialste Lösung. Denn ein Dokument, in dem ein Term häufiger vorkommt als in einem anderes Dokument, weist eine höhere Übereinstimmung mit diesem Term auf.\newpage
Bei dieser Vorgehensweise wird von Term Frequency (siehe \cref{def:TF}) gesprochen, auf deutsch auch als Suchwortdichte bekannt.
\begin{defi}[Term Frequency]\cite[S. 117]{IR_Intro_Cambridge}\label{def:TF}
	Die Term Frequency $\mathtt{tf}_d,_t$ gibt die Anzahl des Terms $t$ in dem Dokument $d$ wieder.
\end{defi}
Bei dieser Vorgehensweise wird jedoch weder die Anordnung der Terme im Dokument, noch die Anordnung der Terme in der Query berücksichtigt. Die Query \glqq Karl ist engagierter als Eckhard\grqq\ liefert die gleiche Gewichtung für die Dokumente einer Kollektion zurück wie \glqq Eckhard ist engagierter als Karl\grqq . Dieses Modell, das die Anordnung der Terme innerhalb des Dokumentes ignoriert, wird auch als \glqq Bag of Words Model\grqq\ bezeichnet. Dieses interpretiert ein Dokument als eine Menge von Tupeln $\langle w_i, k \rangle$, wobei $w_i$ das $i$-te Wort der Menge $W$ ist, welche alle Wörter des Dokuments $d$ beinhaltet. $k$ die Häufigkeit, in der das Wort im Dokument vorkommt. Ein Dokument ist somit ein \glqq Beutel\grqq\ mit vielen losen Wörtern. Daraus folgt, dass zwei Dokumente, welche die selben Wörter und die selbe Anzahl dieser haben, als identisch angesehen werden, obwohl sie das nicht unbedingt sind. Des Weiteren werden alle Terme als gleich wichtig gewertet, was nicht immer zielführend ist, wie zum Beispiel im Abschnitt \ref{sub:tokenerzeugung} mit den \glqq stop words\grqq\ beschrieben wurde.

\section{Inverse Document Frequency}
Da die Terme in einer Suchquery nicht alle von gleicher Bedeutung für die Suche sind, muss eine Lösung gefunden werden, die die Terme untereinander gewichtet. Wenn in einer Dokumenten-Kollektion im Automobilbereich nach \glqq elektrische Autos sind die Zukunft\grqq\ gesucht wird, taucht das Wort Auto in allen Dokumenten häufig auf. Deshalb sollte der Term \glqq Auto\grqq\ weniger stark ins Gewicht fallen als das Wort \glqq elektrische\grqq. Hier kommt die Inverse Document Frequency (siehe \cref{def:IDF}) zum tragen. Jedoch muss vorher geklärt werden worum es sich bei der Document Frequency (siehe \cref{def:DF}) handelt.

\begin{defi}[Document Frequency]\cite[S. 118]{IR_Intro_Cambridge}\label{def:DF}
	Die Document Frequency $\mathtt{df}_t$ gibt die Anzahl der Dokumente $d$ in der genutzten Kollektion an, welche den Term $t$ besitzen.
\end{defi}
\newpage
Durch die Document Frequency kann also festgestellt werden, wie viele Dokumente einen bestimmten Term beinhalten. Die Häufigkeit, in der ein Term in den Dokumenten vorkommt, bleibt dabei unbeachtet, dafür ist die Term Frequency zuständig. Um aus der Document Frequency die einzelnen Terme sinnvoll zu gewichten, wird die Inverse Document Frequency gebildet. 

\begin{defi}[Inverse Document Frequency]\cite[S. 118]{IR_Intro_Cambridge}\label{def:IDF}
	Die Inverse Document Frequency ist definiert als:
	\begin{center}
		$\displaystyle \mathtt{idf}_t = \log(\frac{N_D}{\mathtt{df}_t+1})$
	\end{center}
	$\mathtt{df}_t$ ist hierbei die Document Frequency und $N_D$ die Anzahl der Dokumente in der Kollektion.
\end{defi}

Das Dividieren der Gesamtzahl aller Dokument in der Kollektion ($N_D$) durch die Document Frequency hat zur Folge, dass das Gewicht eines seltenen Terms höher ist und das eines häufigen Terms niedrig. Der Logarithmus sorgt dafür, dass das resultierende Gewicht nicht zu groß wird, wenn die Kollektion sehr groß und der Term selten ist.

\section{Das TF-IDF-Maß}

In diesen Abschnitt wird die Zusammensetzung der Term Frequency und der Inverse Document Frequency zum TF-IDF-Maß beschrieben. 

\begin{defi}[TF-IDF]\cite[S. 119]{IR_Intro_Cambridge}\label{defi:TF-IDF}
	Das TF-IDF-Maß ist wie folgt definiert:
	\begin{center}
		$\displaystyle \mathtt{tf\text{-}idf}_t,_d = \mathtt{tf}_t,_d * \mathtt{idf}_t$
	\end{center}
	Hierbei wird lediglich das Produkt der Inverse Document Frequency mit der Term Frequency gebildet.
\end{defi}

Nun kann eine score-Funktion definiert werden, die einem Dokument ein Gewicht zuweist. Die folgende Funktion $\mathtt{score}(q,d)$ zeigt die Berechnung des Gewichts eines Dokumentes, wobei $q$ hier die Suchquery ist und $d$ das zu gewichtende Dokument:\cite[S. 119]{IR_Intro_Cambridge} 
\begin{center}
	$\displaystyle \mathtt{score}(q,d)=\sum\limits_{t \in q}\mathtt{tf\text{-}idf}_t,_d$
\end{center}
\newpage
Wie in der Funktion beschrieben, wird für jeden Term in der Suchquery das TF-IDF-Maß berechnet. Die einzelnen Gewichte werden dann aufsummiert. Am Ende dieser Prozedur erhält man dann eine Gewichtung für ein Dokument anhand der Suchquery und ist in der Lage seine Relevanz mit der Relevanz der anderen gefundenen Dokumente zu vergleichen.